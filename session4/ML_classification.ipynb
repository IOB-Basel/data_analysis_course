{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets, preprocessing\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, ShuffleSplit\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-entropy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate a range of predicted probabilities (avoiding 0 and 1 to prevent log(0))\n",
    "preds = np.linspace(0.001, 0.999, 200)\n",
    "\n",
    "# Compute losses\n",
    "loss_ce = -np.log(preds)\n",
    "loss_mse = (1 - preds)**2\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(preds, loss_ce, label=\"CE\")\n",
    "plt.plot(preds, loss_mse, label=\"MSE\")\n",
    "\n",
    "plt.xlabel(\"Predicted Probability\")\n",
    "plt.ylabel(\"Log Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "label_map = {index: str(value) for index, value in enumerate(iris.target_names)}\n",
    "\n",
    "\n",
    "df_iris = pd.DataFrame(data=iris[\"data\"], columns=iris[\"feature_names\"])\n",
    "df_iris[\"target\"] = iris.target\n",
    "df_iris[\"target_name\"]= df_iris[\"target\"].replace(label_map)\n",
    "df_iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll only select `versicolor` and `virginica` for binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df_iris[\"target_name\"].str.contains(\"versicolor|virginica\")\n",
    "df_iris_subset = df_iris[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_iris_subset.iloc[:, :4],\n",
    "    df_iris_subset[\"target_name\"],\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    shuffle=True,\n",
    "    stratify=None,\n",
    ")\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create linear regression object (model)\n",
    "logregr = LogisticRegression(penalty=None)\n",
    "\n",
    "# Train the model using the data\n",
    "logregr.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"Accuracy of logistic regression classifier on training set: {logregr.score(X_train_scaled, y_train):.4f}\")\n",
    "print(f\"Accuracy of logistic regression classifier on test set: {logregr.score(X_test_scaled, y_test):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can assess model performace using cross-validation (Note that we are no fune-tuning hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model using ShuffleSplit cross-validation\n",
    "pipeline = Pipeline([(\"scaler\", scaler), (\"fit\", logregr)])\n",
    "shuffle_split = ShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "scores = cross_val_score(pipeline, df_iris_subset.iloc[:, :4], df_iris_subset[\"target\"], cv=shuffle_split)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation for hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the range of regularization parameters\n",
    "Cs = np.logspace(-3, 3, 10)\n",
    "\n",
    "shuffle_split = ShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "clf = LogisticRegressionCV(\n",
    "    Cs=Cs,\n",
    "    cv=shuffle_split,\n",
    ").fit(X_train_scaled, y_train)\n",
    "print(f\"Best regularization strength (C): {clf.C_}\")\n",
    "print(f\"Accuracy on test set: {clf.score(X_test_scaled, y_test):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the coefficients\n",
    "# coefs_paths_ is a dictionary with class labels as keys\n",
    "coefs_paths = clf.coefs_paths_[\"virginica\"]\n",
    "\n",
    "# extract feature names\n",
    "feature_names = df_iris_subset.iloc[:, :4].columns\n",
    "\n",
    "# Plot the coefficient paths for one the cross-validation splits\n",
    "plt.figure(figsize=(5, 4))\n",
    "for i in range(len(feature_names)):\n",
    "    plt.plot(Cs, coefs_paths[0, :, i], label=f\"{feature_names[i]}\")\n",
    "\n",
    "\n",
    "plt.xlabel(\"C\")\n",
    "plt.ylabel(\"Coefficient\")\n",
    "plt.title(\"Logistic Regression Coefficient Paths\")\n",
    "plt.xscale(\"log\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = clf.scores_[\"virginica\"]\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.plot(Cs, scores.mean(axis=0), marker=\"o\", label=\"Mean CV score\")\n",
    "plt.fill_between(\n",
    "    Cs,\n",
    "    scores.mean(axis=0) - scores.std(axis=0),\n",
    "    scores.mean(axis=0) + scores.std(axis=0),\n",
    "    alpha=0.1,\n",
    "    color=\"b\",\n",
    "    label=\"Â± 1 std. dev.\")\n",
    "plt.xscale(\"log\")\n",
    "plt.xlabel(\"C\")\n",
    "plt.ylabel(\"Mean CV Accuracy\")\n",
    "plt.title(\"Cross-Validation accuracy for different regularization strengths\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coefs = pd.DataFrame(\n",
    "    clf.coef_[0],\n",
    "    columns=[\"Coefficients\"],\n",
    "    index=feature_names,\n",
    ")\n",
    "df_coefs.plot.barh(figsize=(5, 4))\n",
    "plt.axvline(x=0, color=\".5\")\n",
    "plt.xlabel(\"coefficient values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "idx = np.where(clf.C_ == Cs)[0]\n",
    "df_coefs = pd.DataFrame(\n",
    "    coefs_paths[:, idx[0], :4],\n",
    "    columns=feature_names,\n",
    ")\n",
    "\n",
    "\n",
    "df_coefs.boxplot(figsize=(5, 4), vert=False)\n",
    "plt.axvline(x=0, color=\".5\")\n",
    "plt.xlabel(\"Coefficient values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "session4_theory",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
